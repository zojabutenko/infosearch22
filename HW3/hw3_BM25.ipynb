{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-RRmH5zEHC"
      },
      "source": [
        "# –î–ó 3 \n",
        "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è BM25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OExAxWc1zEHH"
      },
      "source": [
        "## –§—É–Ω–∫—Ü–∏—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è BM25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMUvekVhzEHI"
      },
      "source": [
        "–î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –µ—Å—Ç—å –æ–±—â–µ–ø—Ä–∏–Ω—è—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
        "–ü—É—Å—Ç—å –¥–∞–Ω –∑–∞–ø—Ä–æ—Å $Query$, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å–ª–æ–≤–∞  $q_1, ... , q_n$, —Ç–æ–≥–¥–∞ —Ñ—É–Ω–∫—Ü–∏—è BM25 –¥–∞—ë—Ç —Å–ª–µ–¥—É—é—â—É—é –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ $Doc$ –∑–∞–ø—Ä–æ—Å—É $Query$:\n",
        "\n",
        "$$ BM25(Query, Doc) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,Doc)*(k+1)}{TF(q_i,Doc)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
        "–≥–¥–µ    \n",
        "$$$$\n",
        "$\\text{IDF}(q_i)$: \n",
        "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
        ">> –≥–¥–µ $N$ - –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ   \n",
        "$n(q_i)$ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Å–ª–æ–≤–æ $q_i$\n",
        "\n",
        ">$TF(q_i,Doc)$ - —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤–∞ $q_i$ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ $Doc$    \n",
        "$k$ –∏ $b$ ‚Äî —Å–≤–æ–±–æ–¥–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã, –æ–±—ã—á–Ω–æ –∏—Ö –≤—ã–±–∏—Ä–∞—é—Ç –∫–∞–∫ $k$=2.0 –∏ $b$=0.75  \n",
        "$l(d)$ - –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –Ω—ë–º)   \n",
        "$avgdl$ ‚Äî —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∫–æ—Ä–ø—É—Å–µ    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlZV395RzEHK"
      },
      "source": [
        "### __–ó–∞–¥–∞—á–∞__:\n",
        "\n",
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–∏—Å–∫, –≥–¥–µ\n",
        "- –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞ - —Å–ª–∞–≥–∞–µ–º—ã–µ **BM25**\n",
        "- —Ñ–æ—Ä–º–∞—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ - **–º–∞—Ç—Ä–∏—Ü–∞ Document-Term**\n",
        "- –º–µ—Ç—Ä–∏–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –ø–∞—Ä (–∑–∞–ø—Ä–æ—Å, –¥–æ–∫—É–º–µ–Ω—Ç) - **BM25**\n",
        "\n",
        "–í —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤—Å–µ —Ç–æ –∂–µ, —á—Ç–æ –≤–æ –≤—Ç–æ—Ä–æ–º –¥–∑:\n",
        "- —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–æ—Ä–ø—É—Å–∞, –Ω–∞ –≤—ã—Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–π –ø–æ—Å—á–∏—Ç–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ Document-Term\n",
        "- —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞, –Ω–∞ –≤—ã—Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–π –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞\n",
        "- —Ñ—É–Ω–∫—Ü–∏—è —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ–¥—Å—á–µ—Ç–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞, –Ω–∞ –≤—ã—Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä, i-–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç –±–ª–∏–∑–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ —Å i-–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º –∫–æ—Ä–ø—É—Å–∞. –°–¥–µ–ª–∞—Ç—å **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ**.\n",
        "- –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –≤—Å–µ —ç—Ç–æ –≤–º–µ—Å—Ç–µ; –Ω–∞ –≤—Ö–æ–¥–µ - –∑–∞–ø—Ä–æ—Å, –Ω–∞ –≤—ã—Ö–æ–¥–µ - –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∏–º–µ–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
        "\n",
        "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ:\n",
        "- —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å **<font color='green'>–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ</font>** —á–µ—Ä–µ–∑ –º–∞—Å–∫—É **(–Ω–∏–∂–µ –¥–∞–Ω –ø—Ä–∏–º–µ—Ä)**; –ø—Ä–∏ –Ω–µ—Å–æ–±–ª—é–¥–µ–Ω–∏–∏ –º–∏–Ω—É—Å –¥–≤–∞ –±–∞–ª–ª–∞\n",
        "- –ø–æ–¥—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å **<font color='green'>–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–∞—Ä—Å-–º–∞—Ç—Ä–∏—Ü</font>**, —Ç–æ –µ—Å—Ç—å –Ω–∏ –≤ –∫–∞–∫–æ–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –≤ ndarray; –ø—Ä–∏ –Ω–µ—Å–æ–±–ª—é–¥–µ–Ω–∏–∏ –º–∏–Ω—É—Å –±–∞–ª–ª\n",
        "\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ—Ä–ø—É—Å–∞ –≤–æ–∑—å–º–∏—Ç–µ –∫–æ—Ä–ø—É—Å –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ —Å –û—Ç–≤–µ—Ç—ã –ú–µ–π–ª) üëçüòÉ \n",
        "[–°—Å—ã–ª–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è](https://www.kaggle.com/bobazooba/thousands-of-questions-about-love)\n",
        "\n",
        "–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ —Å—Å—ã–ª–∫–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞ –±–µ—Ä–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–ª—é—á–∞ *answers*, –Ω–æ –Ω–µ –≤—Å–µ, –∞ –æ–¥–∏–Ω, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π *value*. –ü—Ä–∏ —ç—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ 50000. –ü—Ä–∏–º–µ—Ä –Ω–∏–∂–µ.\n",
        "\n",
        "\n",
        "**–ù–∞ —á—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ —ç—Ç–∞ –∑–∞–¥–∞—á–∞:** \n",
        "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BM25.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMytamDmzEHL",
        "outputId": "cd058fda-8556-480d-d95c-98de0b3c29d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': '–ö—Ç–æ —á—Ç–æ –¥–æ–ª–∂–µ–Ω —Å–¥–µ–ª–∞—Ç—å!? –î–ª—è –∑–∞–≤–æ–µ–≤–∞–Ω–∏—è –¥–æ–≤–µ—Ä–∏—è –∂–µ–Ω—â–∏–Ω—ã —É –º—É–∂—á–∏–Ω—ã –∏ –º—É–∂—á–∏–Ω—ã —É –∂–µ–Ω—â–∏–Ω—ã, –¥–ª—è –ø—Ä–æ—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π!',\n",
              " 'comment': '',\n",
              " 'sub_category': 'relations',\n",
              " 'author': 'Diesel',\n",
              " 'author_rating': {'category': '–ú—ã—Å–ª–∏—Ç–µ–ª—å', 'value': '5175'},\n",
              " 'answers': [{'text': '—ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ–≥–¥–∞ –Ω–∞—Å—Ç–æ–π—á–∏–≤–æ –Ω–∞–≤—è–∑—ã–≤–∞—é—Ç —á—É–≤—Å—Ç–≤–æ –¥–æ–≤–µ—Ä–∏—è',\n",
              "   'author_rating': {'category': '–ó–Ω–∞—Ç–æ–∫', 'value': '312'}},\n",
              "  {'text': '–ü–µ—Ä–µ—Å–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–∞–π—à–Ω–∞–≤–æ–≤. –î–æ–≤–µ—Ä–∏–µ —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –∏–∑ 2 —à—Ç—É–∫. 1. –î–æ–±—Ä–æ—Ç–∞ - –ø–∏–ª–æ—Ç –¥–æ–±—Ä—ã–π, –Ω–æ –Ω–µ —É–º–µ–µ—Ç –≤–æ–¥–∏—Ç—å —Å–∞–º–æ–ª–µ—Ç - –ª–µ—Ç–µ—Ç—å —Å—Ç—Ä–∞—à–Ω–æ, –¥–æ–≤–µ—Ä–∏—è –Ω–µ—Ç. 2. –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º - –∑–∏—Ä—É—Ä–≥ –æ—Ç–ª–∏—á–Ω—ã–π, –Ω–æ —Å–∞–¥–∏—Å—Ç, –æ—Ç—Ä–µ–∂–µ—Ç –ª–∏—à–Ω–µ–µ - –Ω–µ—Ç –¥–æ–≤–µ—Ä–∏—è.–ò—Ç–∞–∫, —É—á–∏—Ç—ã–≤–∞–π—Ç–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫–∞, –ø–æ–≤—ã—à–∞–π—Ç–µ –∞–π–∫—å—é, —á—Ç–æ–± –ø–æ –≤–Ω–µ—à–Ω–µ–º—É –≤–∏–¥—É –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —á–µ —á–µ–ª–æ–≤–µ–∫—É –Ω–∞–¥–æ, –Ω–µ –ø–ª—é–π—Ç–µ –Ω–∞ –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–Ω–µ –ø—Ä–æ—Å–∏—Ç–µ –±–æ–ª—å–Ω–æ–≥–æ –≥—Ä–∏–ø–ø–æ–º –∏–¥—Ç–∏ –¥–ª—è –≤–∞—Å –≤ –∞–ø—Ç–µ–∫—É –∑–∞ –ø—Ä–µ–∑–∏–∫–∞–º–∏), –ø–æ–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤—ã –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—É–¥–µ—Ç–µ –µ–≥–æ –Ω–∞—Å–∏–ª–æ–≤–∞—Ç—å - –≤ —Å–ª—É—á–∞–µ –µ—Å–ª–∏ –≤–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —É—Å—Ç—Ä–æ–∏—Ç –ø—Ä–æ—Å—Ç–æ —É–π–¥–µ—Ç–µ. –ì–æ–≤–æ—Ä–∏—Ç–µ –ø—Ä–∞–≤–¥—É. –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ –Ω–µ –∫–æ—Å—è—á–∏—Ç—å - —Ç–∞–∫—É—é –ø—Ä–∞–≤–¥—É –≥–æ–≤–æ—Ä–∏—Ç—å —Ç—è–∂–µ–ª–æ. –û—Ç–≤–µ—á–∞–π—Ç–µ –∑–∞ —Å–≤–æ–∏ —Å–ª–æ–≤–∞ –∏ –¥–µ–π—Å—Ç–≤–∏—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –í—ã –ø–æ—Ç–µ—Ä—è–ª–∏ –æ–¥–æ–ª–∂–µ–Ω–Ω—É—é –∫–Ω–∏–≥—É, –≤–µ—Ä–Ω–∏—Ç–µ, –Ω–∞–π–¥–∏—Ç–µ —Å–ø–æ—Å–æ–± –ª—é–±–æ–π, —Ö–æ—Ç—å –∏–∑-–ø–æ–¥ –∑–µ–º–ª–∏, –∑–∞–∫–∞–∂–∏—Ç–µ –µ–µ –≤ –∞–º–µ—Ä–∏–∫–µ.',\n",
              "   'author_rating': {'category': '–ì—É—Ä—É', 'value': '3897'}}],\n",
              " 'poll': []}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "import json\n",
        "\n",
        "with open('questions_about_love.jsonl', 'r') as f:\n",
        "    corpus = list(f)[:50000]\n",
        "\n",
        "# –ø—Ä–∏–º–µ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ \n",
        "json.loads(corpus[22])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpKfl-f1zEHN",
        "outputId": "f0ab7f53-acf4-45a9-91cb-5c3fa26662fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['name_6', 'name_5', 'name_4', 'name_2', 'name_1', 'name_3'],\n",
              "      dtype='<U6')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –ø—Ä–∏–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "corpus = [\n",
        "    '–º—ã–ª–∞',\n",
        "    '—Ä–∞–º—É',\n",
        "    '–∫–∏—Å–∞',\n",
        "    '–º–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É',\n",
        "    '–º–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É',\n",
        "    '–º–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É'\n",
        "]\n",
        "corpus_doc_names = np.array(['name_1', 'name_2', 'name_3', 'name_4', 'name_5', 'name_6'])\n",
        "query = '–º–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É'\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "corpus_matrix = vectorizer.fit_transform(corpus)\n",
        "query_vec = vectorizer.transform([query]).toarray()\n",
        "\n",
        "# —Å—á–∏—Ç–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—É—é –±–ª–∏–∑–æ—Å—Ç—å\n",
        "scores = cosine_similarity(corpus_matrix, query_vec)\n",
        "\n",
        "# —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å–∫–æ—Ä–æ–≤ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)\n",
        "sorted_scores_indx = np.argsort(scores, axis=0)[::-1]\n",
        "\n",
        "# —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å–∫–æ—Ä–∞–º–∏\n",
        "corpus_doc_names[sorted_scores_indx.ravel()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djPMQ4eOzEHO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJaRNd6WzEHP",
        "outputId": "4b8b6f6c-0690-455b-b3b5-de89387a934f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4x5 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 3 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø—Ä–æ —Å–ø–∞—Ä—Å-–º–∞—Ç—Ä–∏—Ü—É\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "# –∏—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –Ω–µ–Ω—É–ª–µ–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º —Å–ø–∞—Ä—Å-–º–∞—Ç—Ä–∏—Ü—ã\n",
        "# for i, j in zip(*sparce_matrix.nonzero()): \n",
        "#     ...\n",
        "    \n",
        "# —Å–æ–∑–¥–∞—Ç—å —Å–ø–∞—Ä—Å-–º–∞—Ç—Ä–∏—Ü—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö, –≥–¥–µ\n",
        "# values - –ª–∏—Å—Ç –∏–∑ n –∑–Ω–∞—á–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º –ø–æ–ª–æ–∂–∏—Ç—å –≤ –º–∞—Ç—Ä–∏—Ü—É \n",
        "# rows - –ª–∏—Å—Ç –∏–∑ n –∑–Ω–∞—á–µ–Ω–∏–π, –≥–¥–µ i-—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —ç—Ç–æ –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏ i-–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–∑ values\n",
        "# cols - –ª–∏—Å—Ç –∏–∑ n –∑–Ω–∞—á–µ–Ω–∏–π, –≥–¥–µ i-—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —ç—Ç–æ –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ i-–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–∑ values\n",
        "\n",
        "values = [99, 22, 77]\n",
        "rows = [0, 2, 3]\n",
        "cols = [0, 2, 4]\n",
        "\n",
        "\n",
        "sparse.csr_matrix((values, (rows, cols)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "qhQhKdrHzdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN43PRyNzw1L",
        "outputId": "b746ba36-6512-44af-97b5-1d63166936e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.2 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=523080fa4dcf041f6aeb769f7ad774da900e61d8a512f0bef58b168f07d5ee3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbb5q2J-zlBZ",
        "outputId": "97421c1d-d326-4182-ee8e-caf69084ebbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from scipy import sparse"
      ],
      "metadata": {
        "id": "SRzqD8IqzdKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph = MorphAnalyzer()\n",
        "tokenizer = WordPunctTokenizer()\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"russian\"))\n",
        "count_vectorizer = CountVectorizer()\n",
        "tf_vectorizer = TfidfVectorizer(use_idf=False, norm='l2')\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True, norm='l2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2bLaqbWz80l",
        "outputId": "52139196-c13e-4148-a2eb-08dcc116212f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing"
      ],
      "metadata": {
        "id": "VMQM1elS0ijN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess texts:"
      ],
      "metadata": {
        "id": "weEGjHiG0k1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = tokenizer.tokenize(text.lower())\n",
        "  lemmas = list()\n",
        "  for t in text:\n",
        "    if t not in stop_words and t not in punctuation:\n",
        "      lemmas.append(morph.parse(t)[0].normal_form)\n",
        "\n",
        "  return ' '.join(lemmas)"
      ],
      "metadata": {
        "id": "REBF5T3Rz-d7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gather relevant answers (those with maximum value) from corpus"
      ],
      "metadata": {
        "id": "NpwG62Y21QfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    corpus = list(f)[:50000]\n",
        "  lemmas = list()\n",
        "  texts = list()\n",
        "  for i in corpus:\n",
        "    answers = json.loads(i)['answers']\n",
        "    if answers:\n",
        "      answer_values = np.array(map(int, [i['author_rating']['value'] for i in answers if i != '']))\n",
        "      answer = answers[np.argmax(answer_values)]['text']\n",
        "      lemmas.append(preprocess(answer))\n",
        "      texts.append(answer)\n",
        "  return lemmas, texts"
      ],
      "metadata": {
        "id": "Ztkmwt9t0nLv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build matrix:"
      ],
      "metadata": {
        "id": "Muq0ZTZV1dqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indexes(corpus, k=2, b=0.75):\n",
        "  x_count = count_vectorizer.fit_transform(corpus)\n",
        "  x_idf = tfidf_vectorizer.fit_transform(corpus)\n",
        "  x_tf = tf_vectorizer.fit_transform(corpus)\n",
        "  idf = tfidf_vectorizer.idf_\n",
        "  len_d = x_count.sum(axis=1)\n",
        "  avdl = len_d.mean()\n",
        "  fin = k * (1 - b + b * len_d / avdl)\n",
        "  matrix = sparse.lil_matrix(x_tf.shape)\n",
        "\n",
        "  for i, j in zip(*x_tf.nonzero()):\n",
        "    matrix[i, j] = (x_tf[i, j] * (k + 1) * idf[j])/(x_tf[i, j] + fin[i])\n",
        "    \n",
        "  return matrix.tocsr()"
      ],
      "metadata": {
        "id": "GzxBz51T1Mn6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find(query, corpus, answers):\n",
        "  lemmas = preprocess(query)\n",
        "  if lemmas:\n",
        "    query_index = count_vectorizer.transform([lemmas])\n",
        "    bm25 = corpus.dot(query_index.T)\n",
        "    i = np.argsort(bm25.toarray(), axis=0)\n",
        "    return np.array(answers)[i][::-1].squeeze()\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7G3lmiBK1ko0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/infosearch22/project/data.jsonl'\n",
        "corpus, lemmas = get_relevant(path)\n",
        "matrix = get_indexes(lemmas)\n",
        "qr = input('You may type in your query or \"STOP\" if you want to stop: ')\n",
        "check = True\n",
        "while check == True:\n",
        "  qr = input('You may type in your query or \"STOP\" if you want to stop: ')\n",
        "  if 'STOP' not in qr:\n",
        "    result = find(qr, matrix, corpus)\n",
        "    print(*result[:20])\n",
        "  else:\n",
        "    check = False"
      ],
      "metadata": {
        "id": "YbVcWzXl2Mzi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}